{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0f2d6b",
   "metadata": {},
   "source": [
    "# Chord Detection Notebook\n",
    "This notebook demonstrates an end-to-end pipeline for detecting musical chords from audio files. It covers audio preprocessing, feature extraction, chord recognition, post-processing, batch file handling, and exporting data for Swift integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c586d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.024035Z",
     "iopub.status.busy": "2025-08-20T06:17:15.023577Z",
     "iopub.status.idle": "2025-08-20T06:17:15.600101Z",
     "shell.execute_reply": "2025-08-20T06:17:15.598901Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f01f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.604203Z",
     "iopub.status.busy": "2025-08-20T06:17:15.603619Z",
     "iopub.status.idle": "2025-08-20T06:17:15.611378Z",
     "shell.execute_reply": "2025-08-20T06:17:15.610297Z"
    }
   },
   "outputs": [],
   "source": [
    "PITCH_CLASSES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "def generate_chord_templates():\n",
    "    templates = {}\n",
    "    for i, root in enumerate(PITCH_CLASSES):\n",
    "        major = np.zeros(12)\n",
    "        minor = np.zeros(12)\n",
    "        major[[i, (i+4)%12, (i+7)%12]] = 1\n",
    "        minor[[i, (i+3)%12, (i+7)%12]] = 1\n",
    "        templates[f\"{root}:maj\"] = major\n",
    "        templates[f\"{root}:min\"] = minor\n",
    "        \n",
    "    return templates\n",
    "\n",
    "CHORD_TEMPLATES = generate_chord_templates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da48a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.614941Z",
     "iopub.status.busy": "2025-08-20T06:17:15.614578Z",
     "iopub.status.idle": "2025-08-20T06:17:15.619647Z",
     "shell.execute_reply": "2025-08-20T06:17:15.618688Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_audio(path, target_sr=22050):\n",
    "    y, sr = librosa.load(path, sr=target_sr, mono=True)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "    return y, sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd05bf04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.622851Z",
     "iopub.status.busy": "2025-08-20T06:17:15.622558Z",
     "iopub.status.idle": "2025-08-20T06:17:15.627998Z",
     "shell.execute_reply": "2025-08-20T06:17:15.626870Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(y, sr):\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    pitches = librosa.yin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "    return chroma, pitches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd985eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.630912Z",
     "iopub.status.busy": "2025-08-20T06:17:15.630633Z",
     "iopub.status.idle": "2025-08-20T06:17:15.636967Z",
     "shell.execute_reply": "2025-08-20T06:17:15.635963Z"
    }
   },
   "outputs": [],
   "source": [
    "def recognize_chords(chroma, sr, hop_length=512):\n",
    "    time_stamps = librosa.frames_to_time(np.arange(chroma.shape[1]), sr=sr, hop_length=hop_length)\n",
    "    chords = []\n",
    "    confidences = []\n",
    "    for frame in chroma.T:\n",
    "        scores = {chord: np.dot(frame, template) for chord, template in CHORD_TEMPLATES.items()}\n",
    "        chord = max(scores, key=scores.get)\n",
    "        chords.append(chord)\n",
    "        confidences.append(scores[chord])\n",
    "    return time_stamps, chords, confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25fa3b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.639982Z",
     "iopub.status.busy": "2025-08-20T06:17:15.639628Z",
     "iopub.status.idle": "2025-08-20T06:17:15.645884Z",
     "shell.execute_reply": "2025-08-20T06:17:15.645023Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_chords(chords, confidences, time_stamps):\n",
    "    smoothed = []\n",
    "    times = []\n",
    "    confs = []\n",
    "    prev = None\n",
    "    for chord, conf, t in zip(chords, confidences, time_stamps):\n",
    "        if chord != prev:\n",
    "            smoothed.append(chord)\n",
    "            times.append(t)\n",
    "            confs.append(conf)\n",
    "            prev = chord\n",
    "        else:\n",
    "            confs[-1] = max(confs[-1], conf)\n",
    "    return times, smoothed, confs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5158c2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.649083Z",
     "iopub.status.busy": "2025-08-20T06:17:15.648772Z",
     "iopub.status.idle": "2025-08-20T06:17:15.658725Z",
     "shell.execute_reply": "2025-08-20T06:17:15.657898Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_file(path):\n",
    "    y, sr = preprocess_audio(path)\n",
    "    chroma, pitches = extract_features(y, sr)\n",
    "    times, chords, confs = recognize_chords(chroma, sr)\n",
    "    times, chords, confs = smooth_chords(chords, confs, times)\n",
    "    key = PITCH_CLASSES[np.argmax(chroma.mean(axis=1))]\n",
    "    progression = '-'.join(chords)\n",
    "    mean_conf = float(np.mean(confs))\n",
    "    df_prog = pd.DataFrame({'time': times, 'chord': chords, 'confidence': confs})\n",
    "    return {'song': os.path.basename(path), 'nada_dasar': key, 'chord_progression': progression, 'confidence': mean_conf}, df_prog\n",
    "\n",
    "\n",
    "def process_batch(paths, summary_csv='songs_summary.csv', progression_dir='progressions'):\n",
    "    os.makedirs(progression_dir, exist_ok=True)\n",
    "    summaries = []\n",
    "    for path in paths:\n",
    "        summary, df = process_file(path)\n",
    "        summaries.append(summary)\n",
    "        stem = os.path.splitext(os.path.basename(path))[0]\n",
    "        df.to_csv(os.path.join(progression_dir, f'{stem}_chords.csv'), index=False)\n",
    "    pd.DataFrame(summaries).to_csv(summary_csv, index=False)\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b8c591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.661795Z",
     "iopub.status.busy": "2025-08-20T06:17:15.661497Z",
     "iopub.status.idle": "2025-08-20T06:17:15.666630Z",
     "shell.execute_reply": "2025-08-20T06:17:15.665542Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_templates_json(json_path='chord_templates.json'):\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump({k: v.tolist() for k, v in CHORD_TEMPLATES.items()}, f, indent=2)\n",
    "    return json_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7236ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:15.670022Z",
     "iopub.status.busy": "2025-08-20T06:17:15.669733Z",
     "iopub.status.idle": "2025-08-20T06:17:18.732426Z",
     "shell.execute_reply": "2025-08-20T06:17:18.731251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.11.12/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=690\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'song': 'demo.wav',\n",
       "  'nada_dasar': 'G',\n",
       "  'chord_progression': 'C:maj-G:maj',\n",
       "  'confidence': 2.830510228872299}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage with a synthetic audio file\n",
    "sr = 22050\n",
    "\n",
    "# Generate a C major chord followed by a G major chord\n",
    "def chord_tone(notes, sr, duration):\n",
    "    t = np.linspace(0, duration, int(sr*duration), False)\n",
    "    audio = sum(librosa.tone(librosa.note_to_hz(n), sr=sr, length=len(t)) for n in notes)\n",
    "    return audio / np.max(np.abs(audio))\n",
    "\n",
    "audio = np.concatenate([\n",
    "    chord_tone(['C3','E3','G3'], sr, 1.0),\n",
    "    chord_tone(['G3','B3','D4'], sr, 1.0)\n",
    "])\n",
    "\n",
    "sf.write('demo.wav', audio, sr)\n",
    "process_batch(['demo.wav'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee2d150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:17:18.764211Z",
     "iopub.status.busy": "2025-08-20T06:17:18.763615Z",
     "iopub.status.idle": "2025-08-20T06:17:18.770344Z",
     "shell.execute_reply": "2025-08-20T06:17:18.769152Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "os.remove('demo.wav')\n",
    "os.remove('songs_summary.csv')\n",
    "shutil.rmtree('progressions')\n",
    "if os.path.exists('chord_templates.json'):\n",
    "    os.remove('chord_templates.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
